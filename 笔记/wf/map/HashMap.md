# HashMap 
    HashMap是基于哈希表的Map接口的非同步实现。HashMap允许使用null键和null值。不保证映射的顺序，特别是它不保证该顺序恒久不变。
### 一、数据结构
    在JDK1.8之前数据结构是数据+链表，JDK1.8之后是数据+链表+红黑树（当链表长度大于8时，将链表转换为红黑树）。
    
### 二、工作原理
#### 进行put操作时
* 根据key得到其hashcode值
* 根据hashcode值转换成数组下标
* 如果数组该下标位置为空，则直接存储
* 如果不为空，那么在这个位置上的元素将以链表形式存放，新加入的放在链头，后加入的放在链尾。（JDK1.8后）判断链表长度是否大于8，如果大于就转换为红黑二叉树，并插入树中
* 判断key是否和原有key相同，如果相同就覆盖原有key的value，并返回原有value
* 如果key不相同，就插入一个key，记录结构变化一次
    
#### 进行get操作时
* 判断表或key是否为null,如果是直接返回null
* 判断索引处第一个key与传入key是否相等，如果相等直接返回
* 如果不相等，判断链表是否为红黑树，如果是，直接从树中取值
* 如果不是树，遍历链表查询
    
### 三、扩容机制
*如果两个key的hashcode值相同，那个这两个key在数组中的索引相同，这时就会发生hash冲突。如果HashMap的hash算法越散列，那么发生hash冲突的概率就越低。如果数组长度越大，那么发生hash冲突的概率也会越低。但是数组越大带来的空间开销越多，但是遍历速度越快，这就要在空间和时间上进行权衡。* **负载因子就是权衡过空间和时间得出的**

#### HashMap的resize
当HashMap中的元素越来越多的时候，hash冲突的几率也就越来越高，因为数组的长度是固定的。所以为了提高查询的效率，就要对HashMap的数组进行扩容，数组扩容这个操作也会出现在ArrayList中，这是一个常用的操作，而在HashMap数组扩容之后，最消耗性能的点就出现了：原数组中的数据必须重新计算其在新数组中的位置，并放进去，这就是resize。

那么HashMap什么时候进行扩容呢？当HashMap中的元素个数超过数组大小\*loadFactor时，就会进行数组扩容，loadFactor的默认值为0.75，这是一个折中的取值。也就是说，默认情况下，数组大小为16，那么当HashMap中元素个数超过16\*0.75=12的时候，就把数组的大小扩展为 2*16=32，即扩大一倍，然后重新计算每个元素在数组中的位置，而这是一个非常消耗性能的操作，所以如果我们已经预知HashMap中元素的个数，那么预设元素的个数能够有效的提高HashMap的性能。

#### 为什么HashMap的容量总是2的次幂（假设数组的长度为n）
* 根据hashcode计算index时，假设数组的长度为n，要使得计算出的index在0-n范围内，需要进行hashcode % n 取模运算，但是&比%具有更高的效率。所以就设法用&取代%。
* 当n为2的n次方时，h& (n-1)运算等价于hashcode % n。因为2n-1得到的二进制数的每个位上的值都为1，这使得在低位上&时，得到的和原hash的低位相同。
**（例如n为16，二进制位1111。hashcode二进制为任意数，如10011010，1111 & 10011010 = 1010。这样保证了计算出的结果在0-n范围内，也提高了效率）**
加之hash(int h)方法对key的hashCode的进一步优化，加入了高位计算，就使得只有相同的hash值的两个值才会被放到数组中的同一个位置上形成链表。
* 而如果n不为2的n次方时，不同的hashcode & n计算后的结果可能相同
**（如8 & (15-1)=0100，9 & (15-1)=0100，两者相等）**,此时就会产生碰撞，降低查询效率。而且，当n不为2的n次方时，进行‘与’运算时，最后一位永远是0，而0001，0011，0101，1001，1011，0111，1101这几个位置永远都不能存放元素了，空间浪费相当大，更糟的是这种情况中，数组可以使用的位置比数组长度小了很多，这意味着进一步增加了碰撞的几率，减慢了查询的效率！

### 四、Fail-Fast机制
*由于HashMap不是线程安全的，所有在使用迭代器时，其他进程对map进行了修改，那么将抛出ConcurrentModificationException，这就是所谓fail-fast策略。*

这一策略在源码中的实现是通过modCount域，modCount顾名思义就是修改次数，对HashMap内容的修改都将增加这个值，那么在迭代器初始化过程中会将这个值赋给迭代器的expectedModCount。
 在迭代过程中，判断modCount跟expectedModCount是否相等，如果不相等就表示已经有其他线程修改了Map：
 
 **注意到modCount声明为volatile，保证线程之间修改的可见性。**
 
### 五、为什么HashMap是线程不安全的，实际会如何体现
[HashMap为什么是线程不安全的？](https://blog.csdn.net/mydreamongo/article/details/8960667)
* 如果多个线程同时使用put方法添加元素
假设正好存在两个put的key发生了碰撞(hash值一样)，那么根据HashMap的实现，这两个key会添加到数组的同一个位置，这样最终就会发生其中一个线程的put的数据被覆盖。
* 如果多个线程同时检测到元素个数超过数组大小*loadFactor
这样会发生多个线程同时对hash数组进行扩容，都在重新计算元素位置以及复制数据，但是最终只有一个线程扩容后的数组会赋给table，也就是说其他线程的都会丢失，并且各自线程put的数据也丢失。且会引起死循环的错误。
 
### 六、如何保证HashMap的线程安全
* 替换成Hashtable，Hashtable通过对整个表上锁实现线程安全，因此效率比较低
* 使用Collections类的synchronizedMap方法包装一下
* 使用ConcurrentHashMap，它使用分段锁来保证线程安全
    
### 七、参考博客
[HashMap JDK1.8实现原理](https://www.cnblogs.com/duodushuduokanbao/p/9492952.html)

[深入Java集合学习系列：HashMap的实现原理](http://zhangshixi.iteye.com/blog/672697)

[面试总结HashMap](https://www.cnblogs.com/lchzls/p/6714474.html)